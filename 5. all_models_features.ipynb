{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"new_train.csv\")\n",
    "test = pd.read_csv(\"new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>max_url_per_auction</th>\n",
       "      <th>min_url_per_auction</th>\n",
       "      <th>std_url_per_auction</th>\n",
       "      <th>total_no_of_participated_auctions</th>\n",
       "      <th>no_of_auction_exceeds_threshold</th>\n",
       "      <th>percentage_of_auctions_above_threshold</th>\n",
       "      <th>total_no_of_bidded_category</th>\n",
       "      <th>no_of_merchandise_exceeds_threshold</th>\n",
       "      <th>percentage_of_merchandise_above_threshold</th>\n",
       "      <th>on_url_that_has_a_bot_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.644263</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2008</td>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2009</td>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2011</td>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2012</td>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                              bidder_id  \\\n",
       "0              0  91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1              1  624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2              2  1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3              3  4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4              4  4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...          ...                                    ...   \n",
       "2008        2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009        2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010        2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011        2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012        2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country  ...  max_url_per_auction  min_url_per_auction  \\\n",
       "0       14.0   24.0      6.0  ...                  1.0                  1.0   \n",
       "1        2.0    3.0      1.0  ...                  2.0                  2.0   \n",
       "2        2.0    4.0      1.0  ...                  1.0                  1.0   \n",
       "3        1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "4       53.0  155.0      2.0  ...                 21.0                  1.0   \n",
       "...      ...    ...      ...  ...                  ...                  ...   \n",
       "2008     4.0   33.0      4.0  ...                  1.0                  1.0   \n",
       "2009     1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "2010     2.0    2.0      1.0  ...                  1.0                  1.0   \n",
       "2011     1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "2012     1.0    2.0      1.0  ...                  1.0                  1.0   \n",
       "\n",
       "      std_url_per_auction  total_no_of_participated_auctions  \\\n",
       "0                0.000000                               18.0   \n",
       "1                0.000000                                1.0   \n",
       "2                0.000000                                4.0   \n",
       "3                0.000000                                1.0   \n",
       "4                5.644263                               23.0   \n",
       "...                   ...                                ...   \n",
       "2008             0.000000                               25.0   \n",
       "2009             0.000000                                1.0   \n",
       "2010             0.000000                                1.0   \n",
       "2011             0.000000                                1.0   \n",
       "2012             0.000000                                1.0   \n",
       "\n",
       "      no_of_auction_exceeds_threshold  percentage_of_auctions_above_threshold  \\\n",
       "0                                 0.0                                0.000000   \n",
       "1                                 0.0                                0.000000   \n",
       "2                                 0.0                                0.000000   \n",
       "3                                 0.0                                0.000000   \n",
       "4                                 1.0                                0.043478   \n",
       "...                               ...                                     ...   \n",
       "2008                              1.0                                0.040000   \n",
       "2009                              0.0                                0.000000   \n",
       "2010                              0.0                                0.000000   \n",
       "2011                              0.0                                0.000000   \n",
       "2012                              0.0                                0.000000   \n",
       "\n",
       "      total_no_of_bidded_category  no_of_merchandise_exceeds_threshold  \\\n",
       "0                             1.0                                  0.0   \n",
       "1                             1.0                                  0.0   \n",
       "2                             1.0                                  0.0   \n",
       "3                             1.0                                  0.0   \n",
       "4                             1.0                                  0.0   \n",
       "...                           ...                                  ...   \n",
       "2008                          1.0                                  0.0   \n",
       "2009                          1.0                                  0.0   \n",
       "2010                          1.0                                  0.0   \n",
       "2011                          1.0                                  0.0   \n",
       "2012                          1.0                                  0.0   \n",
       "\n",
       "      percentage_of_merchandise_above_threshold  on_url_that_has_a_bot_mean  \n",
       "0                                           0.0                    1.000000  \n",
       "1                                           0.0                    0.500000  \n",
       "2                                           0.0                    0.500000  \n",
       "3                                           0.0                    1.000000  \n",
       "4                                           0.0                    0.010989  \n",
       "...                                         ...                         ...  \n",
       "2008                                        0.0                    0.500000  \n",
       "2009                                        0.0                    0.000000  \n",
       "2010                                        0.0                    0.000000  \n",
       "2011                                        0.0                    0.000000  \n",
       "2012                                        0.0                    0.000000  \n",
       "\n",
       "[2013 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "test.drop(test.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['bidder_id', 'payment_account', 'address', 'outcome','merchandise']) \n",
    "y = train['outcome']\n",
    "X_test_original = test.drop(columns=['bidder_id', 'payment_account', 'address', 'merchandise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 52)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['auction', 'device', 'time', 'country', 'ip', 'url', 'num_bids',\n",
       "       'num_first_bids', 'num_last_bids', 'time_to_bid', 'inst_resp',\n",
       "       'perc_inst_resp', 'auto parts', 'books and music', 'clothing',\n",
       "       'computers', 'furniture', 'home goods', 'jewelry', 'mobile',\n",
       "       'office equipment', 'sporting goods', 'num_bids_per_auction',\n",
       "       'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip',\n",
       "       'on_ip_that_has_a_bot_mean', 'ip_entropy', 'url_entropy',\n",
       "       'mean_country_per_auction', 'max_country_per_auction',\n",
       "       'min_country_per_auction', 'std_country_per_auction',\n",
       "       'mean_devices_per_auction', 'max_devices_per_auction',\n",
       "       'min_devices_per_auction', 'std_devices_per_auction',\n",
       "       'mean_ip_per_auction', 'max_ip_per_auction', 'min_ip_per_auction',\n",
       "       'std_ip_per_auction', 'mean_url_per_auction', 'max_url_per_auction',\n",
       "       'min_url_per_auction', 'std_url_per_auction',\n",
       "       'total_no_of_participated_auctions', 'no_of_auction_exceeds_threshold',\n",
       "       'percentage_of_auctions_above_threshold', 'total_no_of_bidded_category',\n",
       "       'no_of_merchandise_exceeds_threshold',\n",
       "       'percentage_of_merchandise_above_threshold',\n",
       "       'on_url_that_has_a_bot_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaled_features = data.copy()\n",
    "col_names = ['auction', 'device', 'time', 'country', 'ip', 'url', 'num_bids',\n",
    "       'num_first_bids', 'num_last_bids', 'time_to_bid', 'inst_resp',\n",
    "       'perc_inst_resp', 'num_bids_per_auction',\n",
    "       'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip',\n",
    "       'on_ip_that_has_a_bot_mean', 'ip_entropy', 'url_entropy',\n",
    "       'mean_country_per_auction', 'max_country_per_auction',\n",
    "       'min_country_per_auction', 'std_country_per_auction',\n",
    "       'mean_devices_per_auction', 'max_devices_per_auction',\n",
    "       'min_devices_per_auction', 'std_devices_per_auction',\n",
    "       'mean_ip_per_auction', 'max_ip_per_auction', 'min_ip_per_auction',\n",
    "       'std_ip_per_auction', 'mean_url_per_auction', 'max_url_per_auction',\n",
    "       'min_url_per_auction', 'std_url_per_auction',\n",
    "       'total_no_of_participated_auctions', 'no_of_auction_exceeds_threshold',\n",
    "       'percentage_of_auctions_above_threshold', 'total_no_of_bidded_category',\n",
    "       'no_of_merchandise_exceeds_threshold',\n",
    "       'percentage_of_merchandise_above_threshold',\n",
    "       'on_url_that_has_a_bot_mean']\n",
    "\n",
    "train_features = X[col_names]\n",
    "scaler = StandardScaler().fit(train_features.values)\n",
    "train_features = scaler.transform(train_features.values)\n",
    "X[col_names] = train_features\n",
    "\n",
    "test_features = X_test_original[col_names]\n",
    "scaler_test = StandardScaler().fit(test_features.values)\n",
    "test_features = scaler_test.transform(test_features.values)\n",
    "X_test_original[col_names] = test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    print(\"TRAIN\")\n",
    "    train_predictions = model.predict_proba(X_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "        \n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    train_auc_roc_score = roc_auc_score(y_train,train_predictions[:,1])\n",
    "    train_fbeta = fbeta_score(y_train, train_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_train, train_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_train, train_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(train_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(train_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    print(\"TEST\")\n",
    "    \n",
    "    test_predictions = model.predict_proba(X_test)\n",
    "    test_pred = model.predict(X_test)\n",
    "        \n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_auc_roc_score = roc_auc_score(y_test,test_predictions[:,1])\n",
    "    test_fbeta = fbeta_score(y_test, test_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_test, test_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_test, test_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(test_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(test_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    return [train_accuracy, train_auc_roc_score, train_fbeta, test_accuracy, test_auc_roc_score, test_fbeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(arr):\n",
    "    train_accuracy = []\n",
    "    train_auc_roc_score = [] \n",
    "    train_fbeta = []\n",
    "    test_accuracy = []\n",
    "    test_auc_roc_score = []\n",
    "    test_fbeta = []\n",
    "    \n",
    "    for item in arr:\n",
    "        train_accuracy.append(item[0])\n",
    "        train_auc_roc_score.append(item[1])\n",
    "        train_fbeta.append(item[2])\n",
    "        test_accuracy.append(item[3])\n",
    "        test_auc_roc_score.append(item[4])\n",
    "        test_fbeta.append(item[5])\n",
    "    \n",
    "    mean_accuracy = np.array(train_accuracy).mean()\n",
    "    mean_train_auc_roc_score = np.array(train_auc_roc_score).mean()\n",
    "    mean_train_fbeta = np.array(train_fbeta).mean()\n",
    "    mean_test_accuracy = np.array(test_accuracy).mean()\n",
    "    mean_test_auc_roc_score = np.array(test_auc_roc_score).mean()\n",
    "    mean_test_fbeta = np.array(test_fbeta).mean()\n",
    "    \n",
    "    print(\"final train accuracy: \" + str(mean_accuracy))\n",
    "    print(\"final train AUC: \" + str(mean_train_auc_roc_score))\n",
    "    print(\"final train fbeta: \" + str(mean_train_fbeta))\n",
    "    print(\"final test accuracy: \" + str(mean_test_accuracy))\n",
    "    print(\"final test AUC: \" + str(mean_test_auc_roc_score))\n",
    "    print(\"final test fbeta: \" + str(mean_test_fbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Base Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9694    0.9110    0.9393       382\n",
      "         1.0     0.2273    0.4762    0.3077        21\n",
      "\n",
      "    accuracy                         0.8883       403\n",
      "   macro avg     0.5983    0.6936    0.6235       403\n",
      "weighted avg     0.9307    0.8883    0.9064       403\n",
      "\n",
      "FBeta Score\n",
      "0.39062499999999994\n",
      "Model Performance\n",
      "Accuracy = 0.8883%.\n",
      "AUC ROC = 0.6936%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9677    0.9398    0.9535       382\n",
      "         1.0     0.2812    0.4286    0.3396        21\n",
      "\n",
      "    accuracy                         0.9132       403\n",
      "   macro avg     0.6245    0.6842    0.6466       403\n",
      "weighted avg     0.9319    0.9132    0.9215       403\n",
      "\n",
      "FBeta Score\n",
      "0.3879310344827586\n",
      "Model Performance\n",
      "Accuracy = 0.9132%.\n",
      "AUC ROC = 0.8796%.\n",
      "****************************************************************************************************\n",
      "XGBOOST\n",
      "[14:01:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9681    0.9529    0.9604       382\n",
      "         1.0     0.3333    0.4286    0.3750        21\n",
      "\n",
      "    accuracy                         0.9256       403\n",
      "   macro avg     0.6507    0.6907    0.6677       403\n",
      "weighted avg     0.9350    0.9256    0.9299       403\n",
      "\n",
      "FBeta Score\n",
      "0.4054054054054054\n",
      "Model Performance\n",
      "Accuracy = 0.9256%.\n",
      "AUC ROC = 0.8761%.\n",
      "****************************************************************************************************\n",
      "ANN\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7491    0.8622    0.8017       762\n",
      "         1.0     0.4474    0.2787    0.3434       305\n",
      "\n",
      "    accuracy                         0.6954      1067\n",
      "   macro avg     0.5983    0.5704    0.5726      1067\n",
      "weighted avg     0.6629    0.6954    0.6707      1067\n",
      "\n",
      "FBeta Score\n",
      "0.30141843971631205\n",
      "Model Performance\n",
      "Accuracy = 0.6954%.\n",
      "AUC ROC = 0.3882%.\n",
      "****************************************************************************************************\n",
      "TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9563    0.8586    0.9048       382\n",
      "         1.0     0.1000    0.2857    0.1481        21\n",
      "\n",
      "    accuracy                         0.8288       403\n",
      "   macro avg     0.5281    0.5722    0.5265       403\n",
      "weighted avg     0.9116    0.8288    0.8654       403\n",
      "\n",
      "FBeta Score\n",
      "0.20833333333333331\n",
      "Model Performance\n",
      "Accuracy = 0.8288%.\n",
      "AUC ROC = 0.3611%.\n",
      "****************************************************************************************************\n",
      "Fold number 2\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9649    0.9346    0.9495       382\n",
      "         1.0     0.2424    0.3810    0.2963        21\n",
      "\n",
      "    accuracy                         0.9057       403\n",
      "   macro avg     0.6036    0.6578    0.6229       403\n",
      "weighted avg     0.9272    0.9057    0.9154       403\n",
      "\n",
      "FBeta Score\n",
      "0.3418803418803419\n",
      "Model Performance\n",
      "Accuracy = 0.9057%.\n",
      "AUC ROC = 0.6578%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9787    0.9607    0.9696       382\n",
      "         1.0     0.4643    0.6190    0.5306        21\n",
      "\n",
      "    accuracy                         0.9429       403\n",
      "   macro avg     0.7215    0.7899    0.7501       403\n",
      "weighted avg     0.9519    0.9429    0.9467       403\n",
      "\n",
      "FBeta Score\n",
      "0.5803571428571429\n",
      "Model Performance\n",
      "Accuracy = 0.9429%.\n",
      "AUC ROC = 0.9336%.\n",
      "****************************************************************************************************\n",
      "XGBOOST\n",
      "[14:01:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9761    0.9634    0.9697       382\n",
      "         1.0     0.4615    0.5714    0.5106        21\n",
      "\n",
      "    accuracy                         0.9429       403\n",
      "   macro avg     0.7188    0.7674    0.7402       403\n",
      "weighted avg     0.9493    0.9429    0.9458       403\n",
      "\n",
      "FBeta Score\n",
      "0.5454545454545454\n",
      "Model Performance\n",
      "Accuracy = 0.9429%.\n",
      "AUC ROC = 0.9354%.\n",
      "****************************************************************************************************\n",
      "ANN\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7795    0.7795    0.7795       762\n",
      "         1.0     0.4492    0.4492    0.4492       305\n",
      "\n",
      "    accuracy                         0.6851      1067\n",
      "   macro avg     0.6144    0.6144    0.6144      1067\n",
      "weighted avg     0.6851    0.6851    0.6851      1067\n",
      "\n",
      "FBeta Score\n",
      "0.4491803278688525\n",
      "Model Performance\n",
      "Accuracy = 0.6851%.\n",
      "AUC ROC = 0.4885%.\n",
      "****************************************************************************************************\n",
      "TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9727    0.7461    0.8444       382\n",
      "         1.0     0.1182    0.6190    0.1985        21\n",
      "\n",
      "    accuracy                         0.7395       403\n",
      "   macro avg     0.5454    0.6826    0.5215       403\n",
      "weighted avg     0.9282    0.7395    0.8108       403\n",
      "\n",
      "FBeta Score\n",
      "0.3350515463917526\n",
      "Model Performance\n",
      "Accuracy = 0.7395%.\n",
      "AUC ROC = 0.6451%.\n",
      "****************************************************************************************************\n",
      "Fold number 3\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9748    0.9110    0.9418       382\n",
      "         1.0     0.2609    0.5714    0.3582        21\n",
      "\n",
      "    accuracy                         0.8933       403\n",
      "   macro avg     0.6178    0.7412    0.6500       403\n",
      "weighted avg     0.9376    0.8933    0.9114       403\n",
      "\n",
      "FBeta Score\n",
      "0.4615384615384615\n",
      "Model Performance\n",
      "Accuracy = 0.8933%.\n",
      "AUC ROC = 0.7412%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9733    0.9555    0.9643       382\n",
      "         1.0     0.3929    0.5238    0.4490        21\n",
      "\n",
      "    accuracy                         0.9330       403\n",
      "   macro avg     0.6831    0.7397    0.7067       403\n",
      "weighted avg     0.9431    0.9330    0.9375       403\n",
      "\n",
      "FBeta Score\n",
      "0.4910714285714286\n",
      "Model Performance\n",
      "Accuracy = 0.9330%.\n",
      "AUC ROC = 0.8777%.\n",
      "****************************************************************************************************\n",
      "XGBOOST\n",
      "[14:01:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9708    0.9581    0.9644       382\n",
      "         1.0     0.3846    0.4762    0.4255        21\n",
      "\n",
      "    accuracy                         0.9330       403\n",
      "   macro avg     0.6777    0.7172    0.6950       403\n",
      "weighted avg     0.9403    0.9330    0.9363       403\n",
      "\n",
      "FBeta Score\n",
      "0.45454545454545453\n",
      "Model Performance\n",
      "Accuracy = 0.9330%.\n",
      "AUC ROC = 0.9058%.\n",
      "****************************************************************************************************\n",
      "ANN\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7666    0.8491    0.8057       762\n",
      "         1.0     0.4843    0.3541    0.4091       305\n",
      "\n",
      "    accuracy                         0.7076      1067\n",
      "   macro avg     0.6254    0.6016    0.6074      1067\n",
      "weighted avg     0.6859    0.7076    0.6924      1067\n",
      "\n",
      "FBeta Score\n",
      "0.37422037422037424\n",
      "Model Performance\n",
      "Accuracy = 0.7076%.\n",
      "AUC ROC = 0.4344%.\n",
      "****************************************************************************************************\n",
      "TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9561    0.7984    0.8702       382\n",
      "         1.0     0.0833    0.3333    0.1333        21\n",
      "\n",
      "    accuracy                         0.7742       403\n",
      "   macro avg     0.5197    0.5659    0.5018       403\n",
      "weighted avg     0.9106    0.7742    0.8318       403\n",
      "\n",
      "FBeta Score\n",
      "0.20833333333333331\n",
      "Model Performance\n",
      "Accuracy = 0.7742%.\n",
      "AUC ROC = 0.3939%.\n",
      "****************************************************************************************************\n",
      "Fold number 4\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9886    0.9084    0.9468       382\n",
      "         1.0     0.3137    0.8000    0.4507        20\n",
      "\n",
      "    accuracy                         0.9030       402\n",
      "   macro avg     0.6512    0.8542    0.6987       402\n",
      "weighted avg     0.9550    0.9030    0.9221       402\n",
      "\n",
      "FBeta Score\n",
      "0.6106870229007634\n",
      "Model Performance\n",
      "Accuracy = 0.9030%.\n",
      "AUC ROC = 0.8542%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9837    0.9503    0.9667       382\n",
      "         1.0     0.4242    0.7000    0.5283        20\n",
      "\n",
      "    accuracy                         0.9378       402\n",
      "   macro avg     0.7040    0.8251    0.7475       402\n",
      "weighted avg     0.9559    0.9378    0.9449       402\n",
      "\n",
      "FBeta Score\n",
      "0.6194690265486725\n",
      "Model Performance\n",
      "Accuracy = 0.9378%.\n",
      "AUC ROC = 0.9107%.\n",
      "****************************************************************************************************\n",
      "XGBOOST\n",
      "[14:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9987    1.0000    0.9993       762\n",
      "         1.0     1.0000    0.9967    0.9984       305\n",
      "\n",
      "    accuracy                         0.9991      1067\n",
      "   macro avg     0.9993    0.9984    0.9989      1067\n",
      "weighted avg     0.9991    0.9991    0.9991      1067\n",
      "\n",
      "FBeta Score\n",
      "0.9973753280839895\n",
      "Model Performance\n",
      "Accuracy = 0.9991%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9838    0.9555    0.9695       382\n",
      "         1.0     0.4516    0.7000    0.5490        20\n",
      "\n",
      "    accuracy                         0.9428       402\n",
      "   macro avg     0.7177    0.8277    0.7592       402\n",
      "weighted avg     0.9573    0.9428    0.9485       402\n",
      "\n",
      "FBeta Score\n",
      "0.6306306306306305\n",
      "Model Performance\n",
      "Accuracy = 0.9428%.\n",
      "AUC ROC = 0.9200%.\n",
      "****************************************************************************************************\n",
      "ANN\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7778    0.8543    0.8143       762\n",
      "         1.0     0.5174    0.3902    0.4449       305\n",
      "\n",
      "    accuracy                         0.7216      1067\n",
      "   macro avg     0.6476    0.6222    0.6296      1067\n",
      "weighted avg     0.7033    0.7216    0.7087      1067\n",
      "\n",
      "FBeta Score\n",
      "0.41034482758620683\n",
      "Model Performance\n",
      "Accuracy = 0.7216%.\n",
      "AUC ROC = 0.4416%.\n",
      "****************************************************************************************************\n",
      "TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9564    0.8613    0.9063       382\n",
      "         1.0     0.0862    0.2500    0.1282        20\n",
      "\n",
      "    accuracy                         0.8308       402\n",
      "   macro avg     0.5213    0.5556    0.5173       402\n",
      "weighted avg     0.9131    0.8308    0.8676       402\n",
      "\n",
      "FBeta Score\n",
      "0.18115942028985507\n",
      "Model Performance\n",
      "Accuracy = 0.8308%.\n",
      "AUC ROC = 0.3267%.\n",
      "****************************************************************************************************\n",
      "Fold number 5\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9723    0.9188    0.9448       382\n",
      "         1.0     0.2439    0.5000    0.3279        20\n",
      "\n",
      "    accuracy                         0.8980       402\n",
      "   macro avg     0.6081    0.7094    0.6363       402\n",
      "weighted avg     0.9361    0.8980    0.9141       402\n",
      "\n",
      "FBeta Score\n",
      "0.4132231404958678\n",
      "Model Performance\n",
      "Accuracy = 0.8980%.\n",
      "AUC ROC = 0.7094%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9784    0.9503    0.9641       382\n",
      "         1.0     0.3871    0.6000    0.4706        20\n",
      "\n",
      "    accuracy                         0.9328       402\n",
      "   macro avg     0.6828    0.7751    0.7174       402\n",
      "weighted avg     0.9490    0.9328    0.9396       402\n",
      "\n",
      "FBeta Score\n",
      "0.5405405405405406\n",
      "Model Performance\n",
      "Accuracy = 0.9328%.\n",
      "AUC ROC = 0.8985%.\n",
      "****************************************************************************************************\n",
      "XGBOOST\n",
      "[14:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9785    0.9529    0.9655       382\n",
      "         1.0     0.4000    0.6000    0.4800        20\n",
      "\n",
      "    accuracy                         0.9353       402\n",
      "   macro avg     0.6892    0.7764    0.7228       402\n",
      "weighted avg     0.9497    0.9353    0.9414       402\n",
      "\n",
      "FBeta Score\n",
      "0.5454545454545454\n",
      "Model Performance\n",
      "Accuracy = 0.9353%.\n",
      "AUC ROC = 0.8885%.\n",
      "****************************************************************************************************\n",
      "ANN\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8397    0.7493    0.7920       762\n",
      "         1.0     0.5065    0.6426    0.5665       305\n",
      "\n",
      "    accuracy                         0.7188      1067\n",
      "   macro avg     0.6731    0.6960    0.6792      1067\n",
      "weighted avg     0.7444    0.7188    0.7275      1067\n",
      "\n",
      "FBeta Score\n",
      "0.6098319850653391\n",
      "Model Performance\n",
      "Accuracy = 0.7188%.\n",
      "AUC ROC = 0.6799%.\n",
      "****************************************************************************************************\n",
      "TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9759    0.7408    0.8423       382\n",
      "         1.0     0.1161    0.6500    0.1970        20\n",
      "\n",
      "    accuracy                         0.7363       402\n",
      "   macro avg     0.5460    0.6954    0.5196       402\n",
      "weighted avg     0.9331    0.7363    0.8102       402\n",
      "\n",
      "FBeta Score\n",
      "0.3385416666666667\n",
      "Model Performance\n",
      "Accuracy = 0.7363%.\n",
      "AUC ROC = 0.6493%.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "counter = 1\n",
    "dt_result = []\n",
    "rf_result = []\n",
    "xgb_result = []\n",
    "ann_result = []\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Fold number \" + str(counter))\n",
    "    counter += 1\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # decision tree\n",
    "    print(\"DECISION TREE\")\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_result.append(evaluate(dt, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    # random forest\n",
    "    print(\"RANDOM FOREST\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_result.append(evaluate(rf,X_train,y_train,X_test,y_test))\n",
    "    \n",
    "    # xgboost\n",
    "    print(\"XGBOOST\")\n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_result.append(evaluate(xgb, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    # ann\n",
    "    print(\"ANN\")\n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann.fit(X_train, y_train)\n",
    "    ann_result.append(evaluate(ann, X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy: 1.0\n",
      "final train AUC: 1.0\n",
      "final train fbeta: 1.0\n",
      "final test accuracy: 0.8976679876053973\n",
      "final test AUC: 0.7312341062079282\n",
      "final test fbeta: 0.4435907933630869\n"
     ]
    }
   ],
   "source": [
    "process_results(dt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy: 1.0\n",
      "final train AUC: 1.0\n",
      "final train fbeta: 1.0\n",
      "final test accuracy: 0.9319457304050467\n",
      "final test AUC: 0.9000274245823985\n",
      "final test fbeta: 0.5238738346001087\n"
     ]
    }
   ],
   "source": [
    "process_results(rf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy: 0.9998125585754452\n",
      "final train AUC: 0.9999995697259154\n",
      "final train fbeta: 0.999475065616798\n",
      "final test accuracy: 0.9359196572966433\n",
      "final test AUC: 0.9051570680628271\n",
      "final test fbeta: 0.5162981162981162\n"
     ]
    }
   ],
   "source": [
    "process_results(xgb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy: 0.7057169634489222\n",
      "final train AUC: 0.4865117679962136\n",
      "final train fbeta: 0.4289991908914169\n",
      "final test accuracy: 0.7819191881782157\n",
      "final test AUC: 0.4752013213662429\n",
      "final test fbeta: 0.2542838600029882\n"
     ]
    }
   ],
   "source": [
    "process_results(ann_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_dt(X, y):\n",
    "    print(\"RANDOM SEARCH DECISION TREE EXPERIMENT\")\n",
    "    criterion = ['gini', 'entropy']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [1,2,5,8]\n",
    "    min_samples_leaf = [1,11,21,31]\n",
    "    max_features = [5,10,15,25]\n",
    "    min_impurity_decrease = [0.00005,0.0005,0.005,0.05]\n",
    "\n",
    "    dt_random_grid = {'criterion': criterion,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'max_features': max_features,\n",
    "                   'min_samples_leaf': min_samples_leaf, \n",
    "                   'min_impurity_decrease': min_impurity_decrease}\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt_random = RandomizedSearchCV(estimator = dt, param_distributions = dt_random_grid, n_iter = 100, cv = skf, \n",
    "                               verbose=2, random_state=42, n_jobs = -1, scoring='roc_auc')\n",
    "    dt_random.fit(X_train, y_train)\n",
    "    \n",
    "    dt_best_random = dt_random.best_estimator_\n",
    "    dt_random_accuracy = evaluate(dt_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Random Search Param for DT\")\n",
    "    print(dt_random.best_params_)\n",
    "    \n",
    "def random_search_rf(X, y):\n",
    "    print(\"RANDOM SEARCH RANDOM FOREST EXPERIMENT\")\n",
    "    # parameters for Random Forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_features = ['auto', 'sqrt',5,10,25]\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4,8,10]\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "    # Create the random grid\n",
    "    rf_random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = rf_random_grid, n_iter = 100, cv = skf, verbose=2, \n",
    "                               random_state=42, n_jobs = -1, scoring='roc_auc')\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    rf_best_random = rf_random.best_estimator_\n",
    "    rf_random_accuracy = evaluate(rf_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Random Search Param for RF\")\n",
    "    print(rf_random.best_params_)\n",
    "    \n",
    "def random_search_xgb(X, y):\n",
    "    print(\"RANDOM SEARCH XGB EXPERIMENT\")\n",
    "    xgb_random_grid = {'min_child_weight': range(1,10),\n",
    "                    'gamma': [i/10.0 for i in range(0,10)],\n",
    "                    'subsample': [i/10.0 for i in range(3,10)],\n",
    "                    'colsample_bytree': [i/10.0 for i in range(6,10)],\n",
    "                    'max_depth': [3, 4, 5]}\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "    \n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb_random = RandomizedSearchCV(estimator = xgb, param_distributions = xgb_random_grid, n_iter=100, scoring='roc_auc', \n",
    "                                n_jobs=-1, cv=skf, random_state = 42)\n",
    "    xgb_random.fit(X_train, y_train)\n",
    "    xgb_best_random = xgb_random.best_estimator_\n",
    "    xgb_random_accuracy = evaluate(xgb_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Random Search Param for XGB\")\n",
    "    print(xgb_random.best_params_)\n",
    "    \n",
    "def random_search_ann(X, y):\n",
    "    print(\"RANDOM SEARCH ANN EXPERIMENT\")\n",
    "    learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "    momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "    batch_size = [10, 20, 40, 60, 80, 100]\n",
    "    epochs = [10, 50, 100]\n",
    "\n",
    "    ann_random_grid = dict(learn_rate=learn_rate,momentum=momentum,batch_size=batch_size, epochs=epochs)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann_random = RandomizedSearchCV(estimator = ann, param_distributions = ann_random_grid, n_iter = 100, cv = skf, \n",
    "                                verbose=2, random_state=42, n_jobs = -1, scoring='roc_auc')\n",
    "    ann_random.fit(X_train, y_train)\n",
    "    ann_best_random = ann_random.best_estimator_\n",
    "    ann_random_accuracy = evaluate(ann_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Random Search Param for ANN\")\n",
    "    print(ann_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEARCH DECISION TREE EXPERIMENT\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:    3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9152    0.9414    0.9281       665\n",
      "         1.0     0.8421    0.7820    0.8109       266\n",
      "\n",
      "    accuracy                         0.8958       931\n",
      "   macro avg     0.8787    0.8617    0.8695       931\n",
      "weighted avg     0.8943    0.8958    0.8946       931\n",
      "\n",
      "FBeta Score\n",
      "0.7932875667429442\n",
      "Model Performance\n",
      "Accuracy = 0.8958%.\n",
      "AUC ROC = 0.9650%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9742    0.9151    0.9437       577\n",
      "         1.0     0.2097    0.4815    0.2921        27\n",
      "\n",
      "    accuracy                         0.8957       604\n",
      "   macro avg     0.5919    0.6983    0.6179       604\n",
      "weighted avg     0.9400    0.8957    0.9146       604\n",
      "\n",
      "FBeta Score\n",
      "0.38235294117647056\n",
      "Model Performance\n",
      "Accuracy = 0.8957%.\n",
      "AUC ROC = 0.8106%.\n",
      "****************************************************************************************************\n",
      "Best Random Search Param for DT\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 11, 'min_impurity_decrease': 0.0005, 'max_features': 5, 'max_depth': 100, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "random_search_dt(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEARCH RANDOM FOREST EXPERIMENT\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9955    1.0000    0.9977       665\n",
      "         1.0     1.0000    0.9887    0.9943       266\n",
      "\n",
      "    accuracy                         0.9968       931\n",
      "   macro avg     0.9978    0.9944    0.9960       931\n",
      "weighted avg     0.9968    0.9968    0.9968       931\n",
      "\n",
      "FBeta Score\n",
      "0.9909570459683497\n",
      "Model Performance\n",
      "Accuracy = 0.9968%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9791    0.9723    0.9757       577\n",
      "         1.0     0.4839    0.5556    0.5172        27\n",
      "\n",
      "    accuracy                         0.9536       604\n",
      "   macro avg     0.7315    0.7639    0.7464       604\n",
      "weighted avg     0.9569    0.9536    0.9552       604\n",
      "\n",
      "FBeta Score\n",
      "0.5395683453237411\n",
      "Model Performance\n",
      "Accuracy = 0.9536%.\n",
      "AUC ROC = 0.8943%.\n",
      "****************************************************************************************************\n",
      "Best Random Search Param for RF\n",
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "random_search_rf(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEARCH XGB EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9970    1.0000    0.9985       665\n",
      "         1.0     1.0000    0.9925    0.9962       266\n",
      "\n",
      "    accuracy                         0.9979       931\n",
      "   macro avg     0.9985    0.9962    0.9974       931\n",
      "weighted avg     0.9979    0.9979    0.9978       931\n",
      "\n",
      "FBeta Score\n",
      "0.9939759036144578\n",
      "Model Performance\n",
      "Accuracy = 0.9979%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9807    0.9688    0.9747       577\n",
      "         1.0     0.4706    0.5926    0.5246        27\n",
      "\n",
      "    accuracy                         0.9520       604\n",
      "   macro avg     0.7256    0.7807    0.7497       604\n",
      "weighted avg     0.9579    0.9520    0.9546       604\n",
      "\n",
      "FBeta Score\n",
      "0.5633802816901409\n",
      "Model Performance\n",
      "Accuracy = 0.9520%.\n",
      "AUC ROC = 0.8807%.\n",
      "****************************************************************************************************\n",
      "Best Random Search Param for XGB\n",
      "{'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 0.1, 'colsample_bytree': 0.9}\n"
     ]
    }
   ],
   "source": [
    "random_search_xgb(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 17:04:10.548310: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.548310: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.548317: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.548321: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.548330: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.548335: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.548316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.548320: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 17:04:10.775986: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 17:04:10.776069: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 17:04:10.781973: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 17:04:10.783574: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 17:04:10.783774: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 17:04:10.785738: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 17:04:10.788309: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-07 17:04:10.788659: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8894    0.8827    0.8860       665\n",
      "         1.0     0.7122    0.7256    0.7188       266\n",
      "\n",
      "    accuracy                         0.8378       931\n",
      "   macro avg     0.8008    0.8041    0.8024       931\n",
      "weighted avg     0.8388    0.8378    0.8383       931\n",
      "\n",
      "FBeta Score\n",
      "0.7228464419475655\n",
      "Model Performance\n",
      "Accuracy = 0.8378%.\n",
      "AUC ROC = 0.8592%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9842    0.8614    0.9187       577\n",
      "         1.0     0.1919    0.7037    0.3016        27\n",
      "\n",
      "    accuracy                         0.8543       604\n",
      "   macro avg     0.5880    0.7825    0.6101       604\n",
      "weighted avg     0.9487    0.8543    0.8911       604\n",
      "\n",
      "FBeta Score\n",
      "0.45893719806763283\n",
      "Model Performance\n",
      "Accuracy = 0.8543%.\n",
      "AUC ROC = 0.7871%.\n",
      "****************************************************************************************************\n",
      "Best Random Search Param for ANN\n",
      "{'momentum': 0.2, 'learn_rate': 0.1, 'epochs': 100, 'batch_size': 10}\n"
     ]
    }
   ],
   "source": [
    "random_search_ann(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*****************************************************************************************\n",
    "## Best Random Search Param for DT\n",
    "{'min_samples_split': 2, 'min_samples_leaf': 11, 'min_impurity_decrease': 0.0005, 'max_features': 5, 'max_depth': 100, 'criterion': 'entropy'}\n",
    "\n",
    "## Best Random Search Param for RF\n",
    "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': False}\n",
    "\n",
    "## Best Random Search Param for XGB\n",
    "{'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 0.1, 'colsample_bytree': 0.9}\n",
    "\n",
    "## Best Random Search Param for ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_dt(X, y):\n",
    "    print(\"GRID SEARCH DECISION TREE EXPERIMENT\")\n",
    "    dt_grid = {'criterion': ['entropy'],\n",
    "        'max_depth': [90, 100, 110],\n",
    "        'max_features': [5, 10, 15],\n",
    "        'min_impurity_decrease': [0.0001, 0.0005, 0.001],\n",
    "        'min_samples_leaf': [9,11,13],\n",
    "        'min_samples_split': [1,2,3]\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt_grid = GridSearchCV(estimator = dt, param_grid = dt_grid, cv = skf, n_jobs = -1, verbose = 2, scoring='roc_auc')\n",
    "    dt_grid.fit(X_train, y_train)\n",
    "    \n",
    "    dt_best_grid = dt_grid.best_estimator_\n",
    "    dt_grid_accuracy = evaluate(dt_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Params Grid Search for DT\")\n",
    "    print(dt_grid.best_params_)\n",
    "    \n",
    "    return dt_best_grid\n",
    "    \n",
    "def grid_search_rf(X, y):\n",
    "    print(\"GRID SEARCH RANDOM FOREST EXPERIMENT\")\n",
    "    rf_grid = {\n",
    "        'bootstrap': [False],\n",
    "        'max_depth': [30,40,50],\n",
    "        'max_features': ['auto'],\n",
    "        'min_samples_leaf': [1,2,3],\n",
    "        'min_samples_split': [1,2,3],\n",
    "        'n_estimators': [900,1000,1100]\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_grid = GridSearchCV(estimator = rf, param_grid = rf_grid, cv = skf, n_jobs = -1, verbose = 2, scoring='roc_auc')\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    \n",
    "    rf_best_grid = rf_grid.best_estimator_\n",
    "    rf_grid_accuracy = evaluate(rf_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Params Grid Search for RF\")\n",
    "    print(rf_grid.best_params_)\n",
    "    \n",
    "    return rf_best_grid\n",
    "\n",
    "def grid_search_xgb(X, y):\n",
    "    print(\"GRID SEARCH XGB EXPERIMENT\")\n",
    "    xgb_grid = {\n",
    "        'max_depth':[4,5,6],\n",
    "        'min_child_weight':[1,2,3],\n",
    "        'gamma':[0.1, 0.2, 0.3],\n",
    "        'subsample':[0.7, 0.8, 0.9],\n",
    "        'colsample_bytree':[0.8, 0.9, 1.0]\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "    xgb = XGBClassifier(random_state=42, eval_metric=\"error\")\n",
    "    xgb_grid = GridSearchCV(estimator = xgb, param_grid = xgb_grid, scoring='roc_auc',n_jobs=-1, cv=skf)\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    xgb_best_grid = xgb_grid.best_estimator_\n",
    "    xgb_grid_accuracy = evaluate(xgb_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Params Grid Search for XGB\")\n",
    "    print(xgb_grid.best_params_)\n",
    "\n",
    "    return xgb_best_grid\n",
    "\n",
    "def grid_search_ann(X, y):\n",
    "    learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "    momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "    batch_size = [10, 20, 40, 60, 80, 100]\n",
    "    epochs = [10, 50, 100]\n",
    "    \n",
    "    ann_grid = dict(learn_rate=learn_rate,momentum=momentum,batch_size=batch_size, epochs=epochs)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann_grid = GridSearchCV(estimator = ann, param_grid = ann_grid, n_jobs=-1, cv=skf, scoring='roc_auc')\n",
    "    ann_grid.fit(X_train, y_train)\n",
    "    \n",
    "    ann_best_grid = ann_grid.best_estimator_\n",
    "    ann_grid_accuracy = evaluate(ann_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Params Grid Search for ANN\")\n",
    "    print(ann_grid.best_params_)\n",
    "    return ann_best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH DECISION TREE EXPERIMENT\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 987 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9152    0.9414    0.9281       665\n",
      "         1.0     0.8421    0.7820    0.8109       266\n",
      "\n",
      "    accuracy                         0.8958       931\n",
      "   macro avg     0.8787    0.8617    0.8695       931\n",
      "weighted avg     0.8943    0.8958    0.8946       931\n",
      "\n",
      "FBeta Score\n",
      "0.7932875667429442\n",
      "Model Performance\n",
      "Accuracy = 0.8958%.\n",
      "AUC ROC = 0.9650%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9742    0.9151    0.9437       577\n",
      "         1.0     0.2097    0.4815    0.2921        27\n",
      "\n",
      "    accuracy                         0.8957       604\n",
      "   macro avg     0.5919    0.6983    0.6179       604\n",
      "weighted avg     0.9400    0.8957    0.9146       604\n",
      "\n",
      "FBeta Score\n",
      "0.38235294117647056\n",
      "Model Performance\n",
      "Accuracy = 0.8957%.\n",
      "AUC ROC = 0.8106%.\n",
      "****************************************************************************************************\n",
      "Best Params Grid Search for DT\n",
      "{'criterion': 'entropy', 'max_depth': 90, 'max_features': 5, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 11, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1215 out of 1215 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "dt_best_grid = grid_search_dt(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH RANDOM FOREST EXPERIMENT\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9955    1.0000    0.9977       665\n",
      "         1.0     1.0000    0.9887    0.9943       266\n",
      "\n",
      "    accuracy                         0.9968       931\n",
      "   macro avg     0.9978    0.9944    0.9960       931\n",
      "weighted avg     0.9968    0.9968    0.9968       931\n",
      "\n",
      "FBeta Score\n",
      "0.9909570459683497\n",
      "Model Performance\n",
      "Accuracy = 0.9968%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9791    0.9723    0.9757       577\n",
      "         1.0     0.4839    0.5556    0.5172        27\n",
      "\n",
      "    accuracy                         0.9536       604\n",
      "   macro avg     0.7315    0.7639    0.7464       604\n",
      "weighted avg     0.9569    0.9536    0.9552       604\n",
      "\n",
      "FBeta Score\n",
      "0.5395683453237411\n",
      "Model Performance\n",
      "Accuracy = 0.9536%.\n",
      "AUC ROC = 0.8934%.\n",
      "****************************************************************************************************\n",
      "Best Params Grid Search for RF\n",
      "{'bootstrap': False, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "rf_best_grid = grid_search_rf(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH XGB EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9970    1.0000    0.9985       665\n",
      "         1.0     1.0000    0.9925    0.9962       266\n",
      "\n",
      "    accuracy                         0.9979       931\n",
      "   macro avg     0.9985    0.9962    0.9974       931\n",
      "weighted avg     0.9979    0.9979    0.9978       931\n",
      "\n",
      "FBeta Score\n",
      "0.9939759036144578\n",
      "Model Performance\n",
      "Accuracy = 0.9979%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9773    0.9688    0.9730       577\n",
      "         1.0     0.4375    0.5185    0.4746        27\n",
      "\n",
      "    accuracy                         0.9487       604\n",
      "   macro avg     0.7074    0.7437    0.7238       604\n",
      "weighted avg     0.9531    0.9487    0.9507       604\n",
      "\n",
      "FBeta Score\n",
      "0.5\n",
      "Model Performance\n",
      "Accuracy = 0.9487%.\n",
      "AUC ROC = 0.8895%.\n",
      "****************************************************************************************************\n",
      "Best Params Grid Search for XGB\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.1, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "xgb_best_grid = grid_search_xgb(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9045    0.8827    0.8935       665\n",
      "         1.0     0.7234    0.7669    0.7445       266\n",
      "\n",
      "    accuracy                         0.8496       931\n",
      "   macro avg     0.8139    0.8248    0.8190       931\n",
      "weighted avg     0.8527    0.8496    0.8509       931\n",
      "\n",
      "FBeta Score\n",
      "0.7578008915304606\n",
      "Model Performance\n",
      "Accuracy = 0.8496%.\n",
      "AUC ROC = 0.9052%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9767    0.8700    0.9203       577\n",
      "         1.0     0.1667    0.5556    0.2564        27\n",
      "\n",
      "    accuracy                         0.8560       604\n",
      "   macro avg     0.5717    0.7128    0.5883       604\n",
      "weighted avg     0.9404    0.8560    0.8906       604\n",
      "\n",
      "FBeta Score\n",
      "0.3787878787878788\n",
      "Model Performance\n",
      "Accuracy = 0.8560%.\n",
      "AUC ROC = 0.7055%.\n",
      "****************************************************************************************************\n",
      "Best Params Grid Search for ANN\n",
      "{'batch_size': 60, 'epochs': 100, 'learn_rate': 0.2, 'momentum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "ann_best_grid = grid_search_ann(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Feature Importance of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>rf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_bids_per_device</td>\n",
       "      <td>0.101344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_bids_per_auction</td>\n",
       "      <td>0.093065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inst_resp</td>\n",
       "      <td>0.068570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perc_inst_resp</td>\n",
       "      <td>0.060903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_bids</td>\n",
       "      <td>0.057389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_bids_per_country</td>\n",
       "      <td>0.045099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>0.041678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_bids_per_ip</td>\n",
       "      <td>0.036461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no_of_auction_exceeds_threshold</td>\n",
       "      <td>0.036044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>percentage_of_auctions_above_threshold</td>\n",
       "      <td>0.034575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>time_to_bid</td>\n",
       "      <td>0.027101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>on_url_that_has_a_bot_mean</td>\n",
       "      <td>0.025198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ip_entropy</td>\n",
       "      <td>0.023732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mean_url_per_auction</td>\n",
       "      <td>0.020574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ip</td>\n",
       "      <td>0.020087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>url_entropy</td>\n",
       "      <td>0.020053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max_ip_per_auction</td>\n",
       "      <td>0.016822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_last_bids</td>\n",
       "      <td>0.015239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mean_ip_per_auction</td>\n",
       "      <td>0.015114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mean_devices_per_auction</td>\n",
       "      <td>0.014431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>device</td>\n",
       "      <td>0.014425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>std_ip_per_auction</td>\n",
       "      <td>0.014345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>on_ip_that_has_a_bot_mean</td>\n",
       "      <td>0.014275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>std_country_per_auction</td>\n",
       "      <td>0.012932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>total_no_of_participated_auctions</td>\n",
       "      <td>0.012916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>auction</td>\n",
       "      <td>0.012818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>country</td>\n",
       "      <td>0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>jewelry</td>\n",
       "      <td>0.012278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>num_first_bids</td>\n",
       "      <td>0.012174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mean_country_per_auction</td>\n",
       "      <td>0.011904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>max_country_per_auction</td>\n",
       "      <td>0.011132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>url</td>\n",
       "      <td>0.010830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mobile</td>\n",
       "      <td>0.010441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>max_url_per_auction</td>\n",
       "      <td>0.009343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>std_url_per_auction</td>\n",
       "      <td>0.009323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>std_devices_per_auction</td>\n",
       "      <td>0.009194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>max_devices_per_auction</td>\n",
       "      <td>0.008147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_of_merchandise_exceeds_threshold</td>\n",
       "      <td>0.005726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>percentage_of_merchandise_above_threshold</td>\n",
       "      <td>0.005634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sporting goods</td>\n",
       "      <td>0.005201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>home goods</td>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>computers</td>\n",
       "      <td>0.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>books and music</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>office equipment</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>min_url_per_auction</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>min_ip_per_auction</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>min_country_per_auction</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>min_devices_per_auction</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>total_no_of_bidded_category</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>auto parts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>furniture</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>clothing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Features  rf_weights\n",
       "0                         num_bids_per_device    0.101344\n",
       "1                        num_bids_per_auction    0.093065\n",
       "2                                   inst_resp    0.068570\n",
       "3                              perc_inst_resp    0.060903\n",
       "4                                    num_bids    0.057389\n",
       "5                        num_bids_per_country    0.045099\n",
       "6                                        time    0.041678\n",
       "7                             num_bids_per_ip    0.036461\n",
       "8             no_of_auction_exceeds_threshold    0.036044\n",
       "9      percentage_of_auctions_above_threshold    0.034575\n",
       "10                                time_to_bid    0.027101\n",
       "11                 on_url_that_has_a_bot_mean    0.025198\n",
       "12                                 ip_entropy    0.023732\n",
       "13                       mean_url_per_auction    0.020574\n",
       "14                                         ip    0.020087\n",
       "15                                url_entropy    0.020053\n",
       "16                         max_ip_per_auction    0.016822\n",
       "17                              num_last_bids    0.015239\n",
       "18                        mean_ip_per_auction    0.015114\n",
       "19                   mean_devices_per_auction    0.014431\n",
       "20                                     device    0.014425\n",
       "21                         std_ip_per_auction    0.014345\n",
       "22                  on_ip_that_has_a_bot_mean    0.014275\n",
       "23                    std_country_per_auction    0.012932\n",
       "24          total_no_of_participated_auctions    0.012916\n",
       "25                                    auction    0.012818\n",
       "26                                    country    0.012737\n",
       "27                                    jewelry    0.012278\n",
       "28                             num_first_bids    0.012174\n",
       "29                   mean_country_per_auction    0.011904\n",
       "30                    max_country_per_auction    0.011132\n",
       "31                                        url    0.010830\n",
       "32                                     mobile    0.010441\n",
       "33                        max_url_per_auction    0.009343\n",
       "34                        std_url_per_auction    0.009323\n",
       "35                    std_devices_per_auction    0.009194\n",
       "36                    max_devices_per_auction    0.008147\n",
       "37        no_of_merchandise_exceeds_threshold    0.005726\n",
       "38  percentage_of_merchandise_above_threshold    0.005634\n",
       "39                             sporting goods    0.005201\n",
       "40                                 home goods    0.004192\n",
       "41                                  computers    0.002819\n",
       "42                            books and music    0.001680\n",
       "43                           office equipment    0.001340\n",
       "44                        min_url_per_auction    0.000383\n",
       "45                         min_ip_per_auction    0.000191\n",
       "46                    min_country_per_auction    0.000085\n",
       "47                    min_devices_per_auction    0.000045\n",
       "48                total_no_of_bidded_category    0.000011\n",
       "49                                 auto parts    0.000000\n",
       "50                                  furniture    0.000000\n",
       "51                                   clothing    0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feat_impt = rf_best_grid.feature_importances_\n",
    "rf_features_rank = pd.DataFrame({\"Features\": X.columns, \"rf_weights\": rf_feat_impt})\n",
    "rf_features_rank = rf_features_rank.sort_values(by=['rf_weights'], ascending=False)\n",
    "rf_features_rank = rf_features_rank.reset_index().drop(columns=['index'])\n",
    "rf_features_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>dt_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_bids_per_country</td>\n",
       "      <td>0.555570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_bids_per_ip</td>\n",
       "      <td>0.066281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>time_to_bid</td>\n",
       "      <td>0.048772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time</td>\n",
       "      <td>0.039731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>url_entropy</td>\n",
       "      <td>0.033945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_url_per_auction</td>\n",
       "      <td>0.030475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean_devices_per_auction</td>\n",
       "      <td>0.028039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean_ip_per_auction</td>\n",
       "      <td>0.026810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max_url_per_auction</td>\n",
       "      <td>0.022445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>perc_inst_resp</td>\n",
       "      <td>0.022071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobile</td>\n",
       "      <td>0.020824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ip</td>\n",
       "      <td>0.017186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max_country_per_auction</td>\n",
       "      <td>0.012854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>country</td>\n",
       "      <td>0.012589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ip_entropy</td>\n",
       "      <td>0.008892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>std_devices_per_auction</td>\n",
       "      <td>0.008597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max_devices_per_auction</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_bids_per_auction</td>\n",
       "      <td>0.007070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>device</td>\n",
       "      <td>0.006969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>std_ip_per_auction</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>on_url_that_has_a_bot_mean</td>\n",
       "      <td>0.005985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>num_last_bids</td>\n",
       "      <td>0.005206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>url</td>\n",
       "      <td>0.005163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total_no_of_bidded_category</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>max_ip_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>percentage_of_merchandise_above_threshold</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>no_of_merchandise_exceeds_threshold</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>min_url_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>std_url_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>total_no_of_participated_auctions</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>no_of_auction_exceeds_threshold</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>percentage_of_auctions_above_threshold</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>min_devices_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>min_ip_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>std_country_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>computers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>num_bids</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>num_first_bids</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>inst_resp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>auto parts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>books and music</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>clothing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>furniture</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>min_country_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>home goods</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>jewelry</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>office equipment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sporting goods</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>num_bids_per_device</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mean_country_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>on_ip_that_has_a_bot_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Features  dt_weights\n",
       "0                        num_bids_per_country    0.555570\n",
       "1                             num_bids_per_ip    0.066281\n",
       "2                                 time_to_bid    0.048772\n",
       "3                                        time    0.039731\n",
       "4                                 url_entropy    0.033945\n",
       "5                        mean_url_per_auction    0.030475\n",
       "6                    mean_devices_per_auction    0.028039\n",
       "7                         mean_ip_per_auction    0.026810\n",
       "8                         max_url_per_auction    0.022445\n",
       "9                              perc_inst_resp    0.022071\n",
       "10                                     mobile    0.020824\n",
       "11                                         ip    0.017186\n",
       "12                    max_country_per_auction    0.012854\n",
       "13                                    country    0.012589\n",
       "14                                 ip_entropy    0.008892\n",
       "15                    std_devices_per_auction    0.008597\n",
       "16                    max_devices_per_auction    0.008411\n",
       "17                       num_bids_per_auction    0.007070\n",
       "18                                     device    0.006969\n",
       "19                         std_ip_per_auction    0.006115\n",
       "20                 on_url_that_has_a_bot_mean    0.005985\n",
       "21                              num_last_bids    0.005206\n",
       "22                                        url    0.005163\n",
       "23                total_no_of_bidded_category    0.000000\n",
       "24                         max_ip_per_auction    0.000000\n",
       "25  percentage_of_merchandise_above_threshold    0.000000\n",
       "26        no_of_merchandise_exceeds_threshold    0.000000\n",
       "27                        min_url_per_auction    0.000000\n",
       "28                        std_url_per_auction    0.000000\n",
       "29          total_no_of_participated_auctions    0.000000\n",
       "30            no_of_auction_exceeds_threshold    0.000000\n",
       "31     percentage_of_auctions_above_threshold    0.000000\n",
       "32                    min_devices_per_auction    0.000000\n",
       "33                         min_ip_per_auction    0.000000\n",
       "34                                    auction    0.000000\n",
       "35                    std_country_per_auction    0.000000\n",
       "36                                  computers    0.000000\n",
       "37                                   num_bids    0.000000\n",
       "38                             num_first_bids    0.000000\n",
       "39                                  inst_resp    0.000000\n",
       "40                                 auto parts    0.000000\n",
       "41                            books and music    0.000000\n",
       "42                                   clothing    0.000000\n",
       "43                                  furniture    0.000000\n",
       "44                    min_country_per_auction    0.000000\n",
       "45                                 home goods    0.000000\n",
       "46                                    jewelry    0.000000\n",
       "47                           office equipment    0.000000\n",
       "48                             sporting goods    0.000000\n",
       "49                        num_bids_per_device    0.000000\n",
       "50                   mean_country_per_auction    0.000000\n",
       "51                  on_ip_that_has_a_bot_mean    0.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_feat_impt = dt_best_grid.feature_importances_\n",
    "dt_features_rank = pd.DataFrame({\"Features\": X.columns, \"dt_weights\": dt_feat_impt})\n",
    "dt_features_rank = dt_features_rank.sort_values(by=['dt_weights'], ascending=False)\n",
    "dt_features_rank = dt_features_rank.reset_index().drop(columns=['index'])\n",
    "dt_features_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>xgb_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_bids_per_auction</td>\n",
       "      <td>0.213447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inst_resp</td>\n",
       "      <td>0.106258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_bids_per_device</td>\n",
       "      <td>0.089635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_bids</td>\n",
       "      <td>0.064537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computers</td>\n",
       "      <td>0.031721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_ip_per_auction</td>\n",
       "      <td>0.029687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>percentage_of_auctions_above_threshold</td>\n",
       "      <td>0.025204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_last_bids</td>\n",
       "      <td>0.024257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>device</td>\n",
       "      <td>0.020187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_bids_per_ip</td>\n",
       "      <td>0.020130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>books and music</td>\n",
       "      <td>0.019949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num_first_bids</td>\n",
       "      <td>0.019824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_url_per_auction</td>\n",
       "      <td>0.019629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>url</td>\n",
       "      <td>0.019137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max_country_per_auction</td>\n",
       "      <td>0.016390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>on_url_that_has_a_bot_mean</td>\n",
       "      <td>0.015770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max_ip_per_auction</td>\n",
       "      <td>0.015237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max_devices_per_auction</td>\n",
       "      <td>0.014728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>perc_inst_resp</td>\n",
       "      <td>0.014533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>percentage_of_merchandise_above_threshold</td>\n",
       "      <td>0.014460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mean_url_per_auction</td>\n",
       "      <td>0.013554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>std_devices_per_auction</td>\n",
       "      <td>0.012561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num_bids_per_country</td>\n",
       "      <td>0.012542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>std_ip_per_auction</td>\n",
       "      <td>0.012458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>auction</td>\n",
       "      <td>0.011865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>time</td>\n",
       "      <td>0.011852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ip_entropy</td>\n",
       "      <td>0.011802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>std_country_per_auction</td>\n",
       "      <td>0.011710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sporting goods</td>\n",
       "      <td>0.011652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ip</td>\n",
       "      <td>0.011108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>jewelry</td>\n",
       "      <td>0.010996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>no_of_auction_exceeds_threshold</td>\n",
       "      <td>0.010236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mean_devices_per_auction</td>\n",
       "      <td>0.009916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>time_to_bid</td>\n",
       "      <td>0.008664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>on_ip_that_has_a_bot_mean</td>\n",
       "      <td>0.008008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>country</td>\n",
       "      <td>0.007945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mobile</td>\n",
       "      <td>0.007688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>home goods</td>\n",
       "      <td>0.005944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>max_url_per_auction</td>\n",
       "      <td>0.005866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mean_country_per_auction</td>\n",
       "      <td>0.004011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>url_entropy</td>\n",
       "      <td>0.003345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_of_merchandise_exceeds_threshold</td>\n",
       "      <td>0.001556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>min_devices_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>total_no_of_participated_auctions</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>total_no_of_bidded_category</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>min_url_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>min_country_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>auto parts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>min_ip_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>office equipment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>furniture</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>clothing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Features  xgb_weights\n",
       "0                        num_bids_per_auction     0.213447\n",
       "1                                   inst_resp     0.106258\n",
       "2                         num_bids_per_device     0.089635\n",
       "3                                    num_bids     0.064537\n",
       "4                                   computers     0.031721\n",
       "5                         mean_ip_per_auction     0.029687\n",
       "6      percentage_of_auctions_above_threshold     0.025204\n",
       "7                               num_last_bids     0.024257\n",
       "8                                      device     0.020187\n",
       "9                             num_bids_per_ip     0.020130\n",
       "10                            books and music     0.019949\n",
       "11                             num_first_bids     0.019824\n",
       "12                        std_url_per_auction     0.019629\n",
       "13                                        url     0.019137\n",
       "14                    max_country_per_auction     0.016390\n",
       "15                 on_url_that_has_a_bot_mean     0.015770\n",
       "16                         max_ip_per_auction     0.015237\n",
       "17                    max_devices_per_auction     0.014728\n",
       "18                             perc_inst_resp     0.014533\n",
       "19  percentage_of_merchandise_above_threshold     0.014460\n",
       "20                       mean_url_per_auction     0.013554\n",
       "21                    std_devices_per_auction     0.012561\n",
       "22                       num_bids_per_country     0.012542\n",
       "23                         std_ip_per_auction     0.012458\n",
       "24                                    auction     0.011865\n",
       "25                                       time     0.011852\n",
       "26                                 ip_entropy     0.011802\n",
       "27                    std_country_per_auction     0.011710\n",
       "28                             sporting goods     0.011652\n",
       "29                                         ip     0.011108\n",
       "30                                    jewelry     0.010996\n",
       "31            no_of_auction_exceeds_threshold     0.010236\n",
       "32                   mean_devices_per_auction     0.009916\n",
       "33                                time_to_bid     0.008664\n",
       "34                  on_ip_that_has_a_bot_mean     0.008008\n",
       "35                                    country     0.007945\n",
       "36                                     mobile     0.007688\n",
       "37                                 home goods     0.005944\n",
       "38                        max_url_per_auction     0.005866\n",
       "39                   mean_country_per_auction     0.004011\n",
       "40                                url_entropy     0.003345\n",
       "41        no_of_merchandise_exceeds_threshold     0.001556\n",
       "42                    min_devices_per_auction     0.000000\n",
       "43          total_no_of_participated_auctions     0.000000\n",
       "44                total_no_of_bidded_category     0.000000\n",
       "45                        min_url_per_auction     0.000000\n",
       "46                    min_country_per_auction     0.000000\n",
       "47                                 auto parts     0.000000\n",
       "48                         min_ip_per_auction     0.000000\n",
       "49                           office equipment     0.000000\n",
       "50                                  furniture     0.000000\n",
       "51                                   clothing     0.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_feat_impt = xgb_best_grid.feature_importances_\n",
    "xgb_features_rank = pd.DataFrame({\"Features\": X.columns, \"xgb_weights\": xgb_feat_impt})\n",
    "xgb_features_rank = xgb_features_rank.sort_values(by=['xgb_weights'], ascending=False)\n",
    "xgb_features_rank = xgb_features_rank.reset_index().drop(columns=['index'])\n",
    "xgb_features_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_features_rank.to_csv('rf_features.csv', index=False)\n",
    "# dt_features_rank.to_csv('dt_features.csv', index=False)\n",
    "# xgb_features_rank.to_csv('xgb_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost features</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>time</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ip</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>url</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_bids</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_first_bids</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_last_bids</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time_to_bid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inst_resp</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>computers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jewelry</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num_bids_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>num_bids_per_device</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>num_bids_per_country</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>num_bids_per_ip</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mean_devices_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mean_ip_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mean_url_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>no_of_auction_exceeds_threshold</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>on_url_that_has_a_bot_mean</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   XGBoost features  selected\n",
       "2                              time      True\n",
       "3                           country      True\n",
       "4                                ip      True\n",
       "5                               url      True\n",
       "6                          num_bids      True\n",
       "7                    num_first_bids      True\n",
       "8                     num_last_bids      True\n",
       "9                       time_to_bid      True\n",
       "10                        inst_resp      True\n",
       "15                        computers      True\n",
       "18                          jewelry      True\n",
       "22             num_bids_per_auction      True\n",
       "23              num_bids_per_device      True\n",
       "24             num_bids_per_country      True\n",
       "25                  num_bids_per_ip      True\n",
       "33         mean_devices_per_auction      True\n",
       "37              mean_ip_per_auction      True\n",
       "41             mean_url_per_auction      True\n",
       "46  no_of_auction_exceeds_threshold      True\n",
       "51       on_url_that_has_a_bot_mean      True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "xgb_rfe = RFE(xgb_best_grid, n_features_to_select = 20)\n",
    "xgb_rfe.fit(X_train, y_train)\n",
    "xgb_features = xgb_rfe.support_\n",
    "xgb_features_df = pd.DataFrame({\"XGBoost features\": X.columns, \"selected\":xgb_features})\n",
    "# xgb_features_df\n",
    "xgb_selected_features = xgb_features_df[xgb_features_df['selected'] == True]\n",
    "xgb_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest features</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>time</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ip</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_bids</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time_to_bid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inst_resp</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>perc_inst_resp</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num_bids_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>num_bids_per_device</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>num_bids_per_country</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>num_bids_per_ip</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>on_ip_that_has_a_bot_mean</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ip_entropy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>url_entropy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std_country_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mean_devices_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mean_ip_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mean_url_per_auction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>no_of_auction_exceeds_threshold</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>percentage_of_auctions_above_threshold</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>on_url_that_has_a_bot_mean</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Random Forest features  selected\n",
       "2                                     time      True\n",
       "4                                       ip      True\n",
       "6                                 num_bids      True\n",
       "9                              time_to_bid      True\n",
       "10                               inst_resp      True\n",
       "11                          perc_inst_resp      True\n",
       "22                    num_bids_per_auction      True\n",
       "23                     num_bids_per_device      True\n",
       "24                    num_bids_per_country      True\n",
       "25                         num_bids_per_ip      True\n",
       "26               on_ip_that_has_a_bot_mean      True\n",
       "27                              ip_entropy      True\n",
       "28                             url_entropy      True\n",
       "32                 std_country_per_auction      True\n",
       "33                mean_devices_per_auction      True\n",
       "37                     mean_ip_per_auction      True\n",
       "41                    mean_url_per_auction      True\n",
       "46         no_of_auction_exceeds_threshold      True\n",
       "47  percentage_of_auctions_above_threshold      True\n",
       "51              on_url_that_has_a_bot_mean      True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rfe = RFE(rf_best_grid, n_features_to_select = 20)\n",
    "rf_rfe.fit(X_train, y_train)\n",
    "rf_features = rf_rfe.support_\n",
    "rf_features_df = pd.DataFrame({\"Random Forest features\": X.columns, \"selected\":rf_features})\n",
    "# xgb_features_df\n",
    "rf_selected_features = rf_features_df[rf_features_df['selected'] == True]\n",
    "rf_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
