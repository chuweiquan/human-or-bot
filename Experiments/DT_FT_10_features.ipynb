{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../new_train.csv\")\n",
    "test = pd.read_csv(\"../new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>max_url_per_auction</th>\n",
       "      <th>min_url_per_auction</th>\n",
       "      <th>std_url_per_auction</th>\n",
       "      <th>total_no_of_participated_auctions</th>\n",
       "      <th>no_of_auction_exceeds_threshold</th>\n",
       "      <th>percentage_of_auctions_above_threshold</th>\n",
       "      <th>total_no_of_bidded_category</th>\n",
       "      <th>no_of_merchandise_exceeds_threshold</th>\n",
       "      <th>percentage_of_merchandise_above_threshold</th>\n",
       "      <th>on_url_that_has_a_bot_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.644263</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2008</td>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2009</td>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2011</td>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2012</td>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                              bidder_id  \\\n",
       "0              0  91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1              1  624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2              2  1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3              3  4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4              4  4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...          ...                                    ...   \n",
       "2008        2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009        2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010        2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011        2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012        2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country  ...  max_url_per_auction  min_url_per_auction  \\\n",
       "0       14.0   24.0      6.0  ...                  1.0                  1.0   \n",
       "1        2.0    3.0      1.0  ...                  2.0                  2.0   \n",
       "2        2.0    4.0      1.0  ...                  1.0                  1.0   \n",
       "3        1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "4       53.0  155.0      2.0  ...                 21.0                  1.0   \n",
       "...      ...    ...      ...  ...                  ...                  ...   \n",
       "2008     4.0   33.0      4.0  ...                  1.0                  1.0   \n",
       "2009     1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "2010     2.0    2.0      1.0  ...                  1.0                  1.0   \n",
       "2011     1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "2012     1.0    2.0      1.0  ...                  1.0                  1.0   \n",
       "\n",
       "      std_url_per_auction  total_no_of_participated_auctions  \\\n",
       "0                0.000000                               18.0   \n",
       "1                0.000000                                1.0   \n",
       "2                0.000000                                4.0   \n",
       "3                0.000000                                1.0   \n",
       "4                5.644263                               23.0   \n",
       "...                   ...                                ...   \n",
       "2008             0.000000                               25.0   \n",
       "2009             0.000000                                1.0   \n",
       "2010             0.000000                                1.0   \n",
       "2011             0.000000                                1.0   \n",
       "2012             0.000000                                1.0   \n",
       "\n",
       "      no_of_auction_exceeds_threshold  percentage_of_auctions_above_threshold  \\\n",
       "0                                 0.0                                0.000000   \n",
       "1                                 0.0                                0.000000   \n",
       "2                                 0.0                                0.000000   \n",
       "3                                 0.0                                0.000000   \n",
       "4                                 1.0                                0.043478   \n",
       "...                               ...                                     ...   \n",
       "2008                              1.0                                0.040000   \n",
       "2009                              0.0                                0.000000   \n",
       "2010                              0.0                                0.000000   \n",
       "2011                              0.0                                0.000000   \n",
       "2012                              0.0                                0.000000   \n",
       "\n",
       "      total_no_of_bidded_category  no_of_merchandise_exceeds_threshold  \\\n",
       "0                             1.0                                  0.0   \n",
       "1                             1.0                                  0.0   \n",
       "2                             1.0                                  0.0   \n",
       "3                             1.0                                  0.0   \n",
       "4                             1.0                                  0.0   \n",
       "...                           ...                                  ...   \n",
       "2008                          1.0                                  0.0   \n",
       "2009                          1.0                                  0.0   \n",
       "2010                          1.0                                  0.0   \n",
       "2011                          1.0                                  0.0   \n",
       "2012                          1.0                                  0.0   \n",
       "\n",
       "      percentage_of_merchandise_above_threshold  on_url_that_has_a_bot_mean  \n",
       "0                                           0.0                    1.000000  \n",
       "1                                           0.0                    0.500000  \n",
       "2                                           0.0                    0.500000  \n",
       "3                                           0.0                    1.000000  \n",
       "4                                           0.0                    0.010989  \n",
       "...                                         ...                         ...  \n",
       "2008                                        0.0                    0.500000  \n",
       "2009                                        0.0                    0.000000  \n",
       "2010                                        0.0                    0.000000  \n",
       "2011                                        0.0                    0.000000  \n",
       "2012                                        0.0                    0.000000  \n",
       "\n",
       "[2013 rows x 58 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "test.drop(test.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['bidder_id', 'payment_account', 'address', 'outcome','merchandise']) \n",
    "y = train['outcome']\n",
    "X_test_original = test.drop(columns=['bidder_id', 'payment_account', 'address', 'merchandise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 52)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['auction', 'device', 'time', 'country', 'ip', 'url', 'num_bids',\n",
       "       'num_first_bids', 'num_last_bids', 'time_to_bid', 'inst_resp',\n",
       "       'perc_inst_resp', 'auto parts', 'books and music', 'clothing',\n",
       "       'computers', 'furniture', 'home goods', 'jewelry', 'mobile',\n",
       "       'office equipment', 'sporting goods', 'num_bids_per_auction',\n",
       "       'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip',\n",
       "       'on_ip_that_has_a_bot_mean', 'ip_entropy', 'url_entropy',\n",
       "       'mean_country_per_auction', 'max_country_per_auction',\n",
       "       'min_country_per_auction', 'std_country_per_auction',\n",
       "       'mean_devices_per_auction', 'max_devices_per_auction',\n",
       "       'min_devices_per_auction', 'std_devices_per_auction',\n",
       "       'mean_ip_per_auction', 'max_ip_per_auction', 'min_ip_per_auction',\n",
       "       'std_ip_per_auction', 'mean_url_per_auction', 'max_url_per_auction',\n",
       "       'min_url_per_auction', 'std_url_per_auction',\n",
       "       'total_no_of_participated_auctions', 'no_of_auction_exceeds_threshold',\n",
       "       'percentage_of_auctions_above_threshold', 'total_no_of_bidded_category',\n",
       "       'no_of_merchandise_exceeds_threshold',\n",
       "       'percentage_of_merchandise_above_threshold',\n",
       "       'on_url_that_has_a_bot_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaled_features = data.copy()\n",
    "col_names = ['auction', 'device', 'time', 'country', 'ip', 'url', 'num_bids',\n",
    "       'num_first_bids', 'num_last_bids', 'time_to_bid', 'inst_resp',\n",
    "       'perc_inst_resp', 'num_bids_per_auction',\n",
    "       'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip',\n",
    "       'on_ip_that_has_a_bot_mean', 'ip_entropy', 'url_entropy',\n",
    "       'mean_country_per_auction', 'max_country_per_auction',\n",
    "       'min_country_per_auction', 'std_country_per_auction',\n",
    "       'mean_devices_per_auction', 'max_devices_per_auction',\n",
    "       'min_devices_per_auction', 'std_devices_per_auction',\n",
    "       'mean_ip_per_auction', 'max_ip_per_auction', 'min_ip_per_auction',\n",
    "       'std_ip_per_auction', 'mean_url_per_auction', 'max_url_per_auction',\n",
    "       'min_url_per_auction', 'std_url_per_auction',\n",
    "       'total_no_of_participated_auctions', 'no_of_auction_exceeds_threshold',\n",
    "       'percentage_of_auctions_above_threshold', 'total_no_of_bidded_category',\n",
    "       'no_of_merchandise_exceeds_threshold',\n",
    "       'percentage_of_merchandise_above_threshold',\n",
    "       'on_url_that_has_a_bot_mean']\n",
    "\n",
    "train_features = X[col_names]\n",
    "scaler = StandardScaler().fit(train_features.values)\n",
    "train_features = scaler.transform(train_features.values)\n",
    "X[col_names] = train_features\n",
    "\n",
    "test_features = X_test_original[col_names]\n",
    "scaler_test = StandardScaler().fit(test_features.values)\n",
    "test_features = scaler_test.transform(test_features.values)\n",
    "X_test_original[col_names] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['num_bids_per_ip', 'num_bids_per_auction', 'num_bids_per_country', 'mean_ip_per_auction', 'perc_inst_resp', 'time', 'mean_url_per_auction', 'inst_resp', 'num_bids', 'time_to_bid']\n",
    "X = X[selected_features]\n",
    "X_test_original = X_test_original[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    print(\"TRAIN\")\n",
    "    train_predictions = model.predict_proba(X_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "        \n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    train_auc_roc_score = roc_auc_score(y_train,train_predictions[:,1])\n",
    "    train_fbeta = fbeta_score(y_train, train_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_train, train_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_train, train_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(train_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(train_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    print(\"TEST\")\n",
    "    \n",
    "    test_predictions = model.predict_proba(X_test)\n",
    "    test_pred = model.predict(X_test)\n",
    "        \n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_auc_roc_score = roc_auc_score(y_test,test_predictions[:,1])\n",
    "    test_fbeta = fbeta_score(y_test, test_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_test, test_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_test, test_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(test_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(test_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    return [train_accuracy, train_auc_roc_score, train_fbeta, test_accuracy, test_auc_roc_score, test_fbeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(arr):\n",
    "    train_accuracy = []\n",
    "    train_auc_roc_score = [] \n",
    "    train_fbeta = []\n",
    "    test_accuracy = []\n",
    "    test_auc_roc_score = []\n",
    "    test_fbeta = []\n",
    "    \n",
    "    for item in arr:\n",
    "        train_accuracy.append(item[0])\n",
    "        train_auc_roc_score.append(item[1])\n",
    "        train_fbeta.append(item[2])\n",
    "        test_accuracy.append(item[3])\n",
    "        test_auc_roc_score.append(item[4])\n",
    "        test_fbeta.append(item[5])\n",
    "    \n",
    "    mean_accuracy = np.array(train_accuracy).mean()\n",
    "    mean_train_auc_roc_score = np.array(train_auc_roc_score).mean()\n",
    "    mean_train_fbeta = np.array(train_fbeta).mean()\n",
    "    mean_test_accuracy = np.array(test_accuracy).mean()\n",
    "    mean_test_auc_roc_score = np.array(test_auc_roc_score).mean()\n",
    "    mean_test_fbeta = np.array(test_fbeta).mean()\n",
    "    \n",
    "    print(\"final train accuracy: \" + str(mean_accuracy))\n",
    "    print(\"final train AUC: \" + str(mean_train_auc_roc_score))\n",
    "    print(\"final train fbeta: \" + str(mean_train_fbeta))\n",
    "    print(\"final test accuracy: \" + str(mean_test_accuracy))\n",
    "    print(\"final test AUC: \" + str(mean_test_auc_roc_score))\n",
    "    print(\"final test fbeta: \" + str(mean_test_fbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Base Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9666    0.9084    0.9366       382\n",
      "         1.0     0.2045    0.4286    0.2769        21\n",
      "\n",
      "    accuracy                         0.8834       403\n",
      "   macro avg     0.5856    0.6685    0.6067       403\n",
      "weighted avg     0.9269    0.8834    0.9022       403\n",
      "\n",
      "FBeta Score\n",
      "0.35156249999999994\n",
      "Model Performance\n",
      "Accuracy = 0.8834%.\n",
      "AUC ROC = 0.6685%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9750    0.9188    0.9461       382\n",
      "         1.0     0.2791    0.5714    0.3750        21\n",
      "\n",
      "    accuracy                         0.9007       403\n",
      "   macro avg     0.6270    0.7451    0.6605       403\n",
      "weighted avg     0.9387    0.9007    0.9163       403\n",
      "\n",
      "FBeta Score\n",
      "0.47244094488188976\n",
      "Model Performance\n",
      "Accuracy = 0.9007%.\n",
      "AUC ROC = 0.8743%.\n",
      "****************************************************************************************************\n",
      "Fold number 2\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9773    0.9005    0.9373       382\n",
      "         1.0     0.2549    0.6190    0.3611        21\n",
      "\n",
      "    accuracy                         0.8859       403\n",
      "   macro avg     0.6161    0.7598    0.6492       403\n",
      "weighted avg     0.9396    0.8859    0.9073       403\n",
      "\n",
      "FBeta Score\n",
      "0.48148148148148145\n",
      "Model Performance\n",
      "Accuracy = 0.8859%.\n",
      "AUC ROC = 0.7598%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9730    0.9450    0.9588       382\n",
      "         1.0     0.3438    0.5238    0.4151        21\n",
      "\n",
      "    accuracy                         0.9231       403\n",
      "   macro avg     0.6584    0.7344    0.6870       403\n",
      "weighted avg     0.9403    0.9231    0.9305       403\n",
      "\n",
      "FBeta Score\n",
      "0.4741379310344828\n",
      "Model Performance\n",
      "Accuracy = 0.9231%.\n",
      "AUC ROC = 0.9224%.\n",
      "****************************************************************************************************\n",
      "Fold number 3\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9725    0.9241    0.9477       382\n",
      "         1.0     0.2750    0.5238    0.3607        21\n",
      "\n",
      "    accuracy                         0.9032       403\n",
      "   macro avg     0.6237    0.7239    0.6542       403\n",
      "weighted avg     0.9361    0.9032    0.9171       403\n",
      "\n",
      "FBeta Score\n",
      "0.4435483870967742\n",
      "Model Performance\n",
      "Accuracy = 0.9032%.\n",
      "AUC ROC = 0.7239%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9757    0.9476    0.9615       382\n",
      "         1.0     0.3750    0.5714    0.4528        21\n",
      "\n",
      "    accuracy                         0.9280       403\n",
      "   macro avg     0.6754    0.7595    0.7072       403\n",
      "weighted avg     0.9444    0.9280    0.9350       403\n",
      "\n",
      "FBeta Score\n",
      "0.5172413793103449\n",
      "Model Performance\n",
      "Accuracy = 0.9280%.\n",
      "AUC ROC = 0.8956%.\n",
      "****************************************************************************************************\n",
      "Fold number 4\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9827    0.8901    0.9341       382\n",
      "         1.0     0.2500    0.7000    0.3684        20\n",
      "\n",
      "    accuracy                         0.8806       402\n",
      "   macro avg     0.6163    0.7950    0.6512       402\n",
      "weighted avg     0.9462    0.8806    0.9059       402\n",
      "\n",
      "FBeta Score\n",
      "0.5147058823529412\n",
      "Model Performance\n",
      "Accuracy = 0.8806%.\n",
      "AUC ROC = 0.7950%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9987    1.0000    0.9993       762\n",
      "         1.0     1.0000    0.9967    0.9984       305\n",
      "\n",
      "    accuracy                         0.9991      1067\n",
      "   macro avg     0.9993    0.9984    0.9989      1067\n",
      "weighted avg     0.9991    0.9991    0.9991      1067\n",
      "\n",
      "FBeta Score\n",
      "0.9973753280839895\n",
      "Model Performance\n",
      "Accuracy = 0.9991%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9828    0.8979    0.9384       382\n",
      "         1.0     0.2642    0.7000    0.3836        20\n",
      "\n",
      "    accuracy                         0.8881       402\n",
      "   macro avg     0.6235    0.7990    0.6610       402\n",
      "weighted avg     0.9471    0.8881    0.9108       402\n",
      "\n",
      "FBeta Score\n",
      "0.5263157894736842\n",
      "Model Performance\n",
      "Accuracy = 0.8881%.\n",
      "AUC ROC = 0.9014%.\n",
      "****************************************************************************************************\n",
      "Fold number 5\n",
      "DECISION TREE\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9725    0.9267    0.9491       382\n",
      "         1.0     0.2632    0.5000    0.3448        20\n",
      "\n",
      "    accuracy                         0.9055       402\n",
      "   macro avg     0.6178    0.7134    0.6469       402\n",
      "weighted avg     0.9372    0.9055    0.9190       402\n",
      "\n",
      "FBeta Score\n",
      "0.423728813559322\n",
      "Model Performance\n",
      "Accuracy = 0.9055%.\n",
      "AUC ROC = 0.7134%.\n",
      "****************************************************************************************************\n",
      "RANDOM FOREST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       762\n",
      "         1.0     1.0000    1.0000    1.0000       305\n",
      "\n",
      "    accuracy                         1.0000      1067\n",
      "   macro avg     1.0000    1.0000    1.0000      1067\n",
      "weighted avg     1.0000    1.0000    1.0000      1067\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9862    0.9346    0.9597       382\n",
      "         1.0     0.3750    0.7500    0.5000        20\n",
      "\n",
      "    accuracy                         0.9254       402\n",
      "   macro avg     0.6806    0.8423    0.7298       402\n",
      "weighted avg     0.9558    0.9254    0.9368       402\n",
      "\n",
      "FBeta Score\n",
      "0.625\n",
      "Model Performance\n",
      "Accuracy = 0.9254%.\n",
      "AUC ROC = 0.9084%.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "counter = 1\n",
    "dt_result = []\n",
    "rf_result = []\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Fold number \" + str(counter))\n",
    "    counter += 1\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # decision tree\n",
    "    print(\"DECISION TREE\")\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_result.append(evaluate(dt, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    # random forest\n",
    "    print(\"RANDOM FOREST\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_result.append(evaluate(rf,X_train,y_train,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy: 1.0\n",
      "final train AUC: 1.0\n",
      "final train fbeta: 1.0\n",
      "final test accuracy: 0.8917052454847351\n",
      "final test AUC: 0.7321166791323859\n",
      "final test fbeta: 0.44300541289810375\n"
     ]
    }
   ],
   "source": [
    "process_results(dt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train accuracy: 0.9998125585754452\n",
      "final train AUC: 1.0\n",
      "final train fbeta: 0.999475065616798\n",
      "final test accuracy: 0.9130587756009035\n",
      "final test AUC: 0.9004325604587384\n",
      "final test fbeta: 0.5230272089400804\n"
     ]
    }
   ],
   "source": [
    "process_results(rf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_dt(X, y):\n",
    "    print(\"RANDOM SEARCH DECISION TREE EXPERIMENT\")\n",
    "    criterion = ['gini', 'entropy']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [1,2,5,8]\n",
    "    min_samples_leaf = [1,11,21,31]\n",
    "    max_features = [5,10,15,25]\n",
    "    min_impurity_decrease = [0.00005,0.0005,0.005,0.05]\n",
    "\n",
    "    dt_random_grid = {'criterion': criterion,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'max_features': max_features,\n",
    "                   'min_samples_leaf': min_samples_leaf, \n",
    "                   'min_impurity_decrease': min_impurity_decrease}\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt_random = RandomizedSearchCV(estimator = dt, param_distributions = dt_random_grid, n_iter = 100, cv = skf, \n",
    "                               verbose=2, random_state=42, n_jobs = -1, scoring='roc_auc')\n",
    "    dt_random.fit(X_train, y_train)\n",
    "    \n",
    "    dt_best_random = dt_random.best_estimator_\n",
    "    dt_random_accuracy = evaluate(dt_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Random Search Param for DT\")\n",
    "    print(dt_random.best_params_)\n",
    "    \n",
    "def random_search_rf(X, y):\n",
    "    print(\"RANDOM SEARCH RANDOM FOREST EXPERIMENT\")\n",
    "    # parameters for Random Forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_features = ['auto', 'sqrt',5,10,25]\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4,8,10]\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "    # Create the random grid\n",
    "    rf_random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = rf_random_grid, n_iter = 100, cv = skf, verbose=2, \n",
    "                               random_state=42, n_jobs = -1, scoring='roc_auc')\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    rf_best_random = rf_random.best_estimator_\n",
    "    rf_random_accuracy = evaluate(rf_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Random Search Param for RF\")\n",
    "    print(rf_random.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEARCH DECISION TREE EXPERIMENT\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9273    0.9398    0.9335       665\n",
      "         1.0     0.8444    0.8158    0.8298       266\n",
      "\n",
      "    accuracy                         0.9044       931\n",
      "   macro avg     0.8858    0.8778    0.8817       931\n",
      "weighted avg     0.9036    0.9044    0.9039       931\n",
      "\n",
      "FBeta Score\n",
      "0.8213474640423922\n",
      "Model Performance\n",
      "Accuracy = 0.9044%.\n",
      "AUC ROC = 0.9598%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9792    0.8977    0.9367       577\n",
      "         1.0     0.2133    0.5926    0.3137        27\n",
      "\n",
      "    accuracy                         0.8841       604\n",
      "   macro avg     0.5963    0.7452    0.6252       604\n",
      "weighted avg     0.9450    0.8841    0.9089       604\n",
      "\n",
      "FBeta Score\n",
      "0.4371584699453551\n",
      "Model Performance\n",
      "Accuracy = 0.8841%.\n",
      "AUC ROC = 0.8473%.\n",
      "****************************************************************************************************\n",
      "Best Random Search Param for DT\n",
      "{'min_samples_split': 5, 'min_samples_leaf': 21, 'min_impurity_decrease': 5e-05, 'max_features': 5, 'max_depth': 110, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "random_search_dt(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEARCH RANDOM FOREST EXPERIMENT\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9955    0.9985    0.9970       665\n",
      "         1.0     0.9962    0.9887    0.9925       266\n",
      "\n",
      "    accuracy                         0.9957       931\n",
      "   macro avg     0.9959    0.9936    0.9947       931\n",
      "weighted avg     0.9957    0.9957    0.9957       931\n",
      "\n",
      "FBeta Score\n",
      "0.990210843373494\n",
      "Model Performance\n",
      "Accuracy = 0.9957%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9730    0.9359    0.9541       577\n",
      "         1.0     0.2449    0.4444    0.3158        27\n",
      "\n",
      "    accuracy                         0.9139       604\n",
      "   macro avg     0.6089    0.6902    0.6349       604\n",
      "weighted avg     0.9404    0.9139    0.9255       604\n",
      "\n",
      "FBeta Score\n",
      "0.38216560509554137\n",
      "Model Performance\n",
      "Accuracy = 0.9139%.\n",
      "AUC ROC = 0.8602%.\n",
      "****************************************************************************************************\n",
      "Best Random Search Param for RF\n",
      "{'n_estimators': 1600, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "random_search_rf(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*****************************************************************************************\n",
    "## Best Random Search Param for DT\n",
    "{'min_samples_split': 5, 'min_samples_leaf': 21, 'min_impurity_decrease': 5e-05, 'max_features': 5, 'max_depth': 110, 'criterion': 'gini'}\n",
    "\n",
    "## Best Random Search Param for RF\n",
    "{'n_estimators': 1600, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_dt(X, y):\n",
    "    print(\"GRID SEARCH DECISION TREE EXPERIMENT\")\n",
    "    dt_grid = {'criterion': ['entropy'],\n",
    "        'max_depth': [100, 110, 120],\n",
    "        'max_features': [4, 5, 6],\n",
    "        'min_impurity_decrease': [5e-06, 5e-05, 5e-04],\n",
    "        'min_samples_leaf': [19,21,23],\n",
    "        'min_samples_split': [4,5,6]\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt_grid = GridSearchCV(estimator = dt, param_grid = dt_grid, cv = skf, n_jobs = -1, verbose = 2, scoring='roc_auc')\n",
    "    dt_grid.fit(X_train, y_train)\n",
    "    \n",
    "    dt_best_grid = dt_grid.best_estimator_\n",
    "    dt_grid_accuracy = evaluate(dt_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Params Grid Search for DT\")\n",
    "    print(dt_grid.best_params_)\n",
    "    \n",
    "    return dt_best_grid\n",
    "    \n",
    "def grid_search_rf(X, y):\n",
    "    print(\"GRID SEARCH RANDOM FOREST EXPERIMENT\")\n",
    "    rf_grid = {\n",
    "        'bootstrap': [False],\n",
    "        'max_depth': [90,100,110],\n",
    "        'max_features': ['auto'],\n",
    "        'min_samples_leaf': [1,2,3],\n",
    "        'min_samples_split': [1,2,3],\n",
    "        'n_estimators': [1500,1600,1700]\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_grid = GridSearchCV(estimator = rf, param_grid = rf_grid, cv = skf, n_jobs = -1, verbose = 2, scoring='roc_auc')\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    \n",
    "    rf_best_grid = rf_grid.best_estimator_\n",
    "    rf_grid_accuracy = evaluate(rf_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Params Grid Search for RF\")\n",
    "    print(rf_grid.best_params_)\n",
    "    \n",
    "    return rf_best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH DECISION TREE EXPERIMENT\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1002 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1215 out of 1215 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9138    0.9564    0.9346       665\n",
      "         1.0     0.8766    0.7744    0.8224       266\n",
      "\n",
      "    accuracy                         0.9044       931\n",
      "   macro avg     0.8952    0.8654    0.8785       931\n",
      "weighted avg     0.9032    0.9044    0.9025       931\n",
      "\n",
      "FBeta Score\n",
      "0.7929176289453426\n",
      "Model Performance\n",
      "Accuracy = 0.9044%.\n",
      "AUC ROC = 0.9611%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9799    0.9272    0.9528       577\n",
      "         1.0     0.2759    0.5926    0.3765        27\n",
      "\n",
      "    accuracy                         0.9123       604\n",
      "   macro avg     0.6279    0.7599    0.6646       604\n",
      "weighted avg     0.9484    0.9123    0.9270       604\n",
      "\n",
      "FBeta Score\n",
      "0.48192771084337355\n",
      "Model Performance\n",
      "Accuracy = 0.9123%.\n",
      "AUC ROC = 0.8746%.\n",
      "****************************************************************************************************\n",
      "Best Params Grid Search for DT\n",
      "{'criterion': 'entropy', 'max_depth': 100, 'max_features': 5, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 21, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "dt_best_grid = grid_search_dt(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH RANDOM FOREST EXPERIMENT\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9955    0.9985    0.9970       665\n",
      "         1.0     0.9962    0.9887    0.9925       266\n",
      "\n",
      "    accuracy                         0.9957       931\n",
      "   macro avg     0.9959    0.9936    0.9947       931\n",
      "weighted avg     0.9957    0.9957    0.9957       931\n",
      "\n",
      "FBeta Score\n",
      "0.990210843373494\n",
      "Model Performance\n",
      "Accuracy = 0.9957%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9730    0.9376    0.9550       577\n",
      "         1.0     0.2500    0.4444    0.3200        27\n",
      "\n",
      "    accuracy                         0.9156       604\n",
      "   macro avg     0.6115    0.6910    0.6375       604\n",
      "weighted avg     0.9407    0.9156    0.9266       604\n",
      "\n",
      "FBeta Score\n",
      "0.38461538461538464\n",
      "Model Performance\n",
      "Accuracy = 0.9156%.\n",
      "AUC ROC = 0.8602%.\n",
      "****************************************************************************************************\n",
      "Best Params Grid Search for RF\n",
      "{'bootstrap': False, 'max_depth': 90, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 1700}\n"
     ]
    }
   ],
   "source": [
    "rf_best_grid = grid_search_rf(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
